{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6e83cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the essential libraries \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16;\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddcb7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading mnist dataset from keras\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adc3e8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#trainX is an array, etc, arraying from 0-255\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afc14414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 84), (10000, 28, 84))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX=np.dstack([trainX] * 3)\n",
    "testX=np.dstack([testX]*3)\n",
    "trainX.shape,testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "352b4bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 3), (10000, 28, 28, 3))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape images as per the tensor format required by tensorflow\n",
    "trainX = trainX.reshape(-1, 28,28,3)\n",
    "testX= testX.reshape (-1,28,28,3)\n",
    "trainX.shape,testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ca1e2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resize the images 48*48 as required by VGG16\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "trainX = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in trainX])\n",
    "testX = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in testX])\n",
    "\n",
    "#trainx = preprocess_input(x)\n",
    "trainX.shape, testX.shape\n",
    "classes = np.unique(trainY)\n",
    "num_classes = len(classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "145f53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data and change data type\n",
    "trainX = trainX / 255.\n",
    "testX = testX / 255.\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6ef4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting Labels to one hot encoded format\n",
    "trainY_one_hot = to_categorical(trainY)\n",
    "testY_one_hot = to_categorical(testY)\n",
    "\n",
    "trainX,valid_X,train_label,valid_label = train_test_split(trainX, trainY_one_hot,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53541c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#finally check the data size whether it is as per tensorflow and VGG16 requirement\n",
    "trainX.shape,valid_X.shape,train_label.shape,valid_label.shape\n",
    "\n",
    "#define the parameters for instanitaing VGG16 model. \n",
    "IMG_WIDTH = 48\n",
    "IMG_HEIGHT = 48\n",
    "IMG_DEPTH = 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#preprocessing the input \n",
    "trainX = preprocess_input(trainX)\n",
    "valid_X = preprocess_input(valid_X)\n",
    "testX  = preprocess_input (testX)\n",
    "\n",
    "#create base model of VGG16\n",
    "conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ab53af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 980s 327ms/step\n",
      "625/625 [==============================] - 151s 242ms/step\n",
      "750/750 [==============================] - 181s 241ms/step\n"
     ]
    }
   ],
   "source": [
    "#extracting features\n",
    "train_features = conv_base.predict(np.array(trainX), batch_size=BATCH_SIZE, verbose=1)\n",
    "test_features = conv_base.predict(np.array(testX), batch_size=BATCH_SIZE, verbose=1)\n",
    "val_features = conv_base.predict(np.array(valid_X), batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22e548d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the features so that they can be used for future\n",
    "np.savez(\"train_features\", train_features, train_label)\n",
    "np.savez(\"test_features\", test_features, testY)\n",
    "np.savez(\"val_features\", val_features, valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b45a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 1, 1, 512) \n",
      " (10000, 1, 1, 512) \n",
      " (12000, 1, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "train_features_flat = np.reshape(train_features, (48000, 1*1*512))\n",
    "test_features_flat = np.reshape(test_features, (10000, 1*1*512))\n",
    "val_features_flat = np.reshape(val_features, (12000, 1*1*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03e93ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "580b6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_TRAIN_SAMPLES = train_features_flat.shape[0]\n",
    "NB_VALIDATION_SAMPLES = val_features_flat.shape[0]\n",
    "NB_EPOCHS = 100\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=(1*1*512)))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b86669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92e1a0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "reduce_learning = callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=2,verbose=1,mode='auto',epsilon=0.0001,cooldown=2,min_lr=0)\n",
    "eary_stopping = callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=7,verbose=1,mode='auto')\n",
    "callbacks = [reduce_learning, eary_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4055434c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.4029 - acc: 0.5027 - val_loss: 1.1159 - val_acc: 0.6132\n",
      "Epoch 2/100\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.9956 - acc: 0.6545 - val_loss: 0.9222 - val_acc: 0.6880\n",
      "Epoch 3/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8811 - acc: 0.6974 - val_loss: 0.8306 - val_acc: 0.7152\n",
      "Epoch 4/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8077 - acc: 0.7267 - val_loss: 0.7674 - val_acc: 0.7370\n",
      "Epoch 5/100\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.7633 - acc: 0.7389 - val_loss: 0.6876 - val_acc: 0.7731\n",
      "Epoch 6/100\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7266 - acc: 0.7535 - val_loss: 0.7686 - val_acc: 0.7327\n",
      "Epoch 7/100\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.7064 - acc: 0.7609- E\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.7060 - acc: 0.7609 - val_loss: 0.6883 - val_acc: 0.7645\n",
      "Epoch 8/100\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6074 - acc: 0.8015 - val_loss: 0.5864 - val_acc: 0.8084\n",
      "Epoch 9/100\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5980 - acc: 0.8053 - val_loss: 0.5897 - val_acc: 0.8037\n",
      "Epoch 10/100\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.5912 - acc: 0.8069\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5912 - acc: 0.8070 - val_loss: 0.5932 - val_acc: 0.8045\n",
      "Epoch 11/100\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5681 - acc: 0.8159 - val_loss: 0.5613 - val_acc: 0.8177\n",
      "Epoch 12/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5652 - acc: 0.8172 - val_loss: 0.5625 - val_acc: 0.8177\n",
      "Epoch 13/100\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5637 - acc: 0.8181 - val_loss: 0.5593 - val_acc: 0.8185\n",
      "Epoch 14/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5614 - acc: 0.8185 - val_loss: 0.5603 - val_acc: 0.8194\n",
      "Epoch 15/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5596 - acc: 0.8189 - val_loss: 0.5586 - val_acc: 0.8170\n",
      "Epoch 16/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5582 - acc: 0.8197 - val_loss: 0.5553 - val_acc: 0.8182\n",
      "Epoch 17/100\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.5567 - acc: 0.8195 - val_loss: 0.5618 - val_acc: 0.8164\n",
      "Epoch 18/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5551 - acc: 0.8205 - val_loss: 0.5541 - val_acc: 0.8184\n",
      "Epoch 19/100\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5540 - acc: 0.8205 - val_loss: 0.5519 - val_acc: 0.8220\n",
      "Epoch 20/100\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5521 - acc: 0.8212 - val_loss: 0.5522 - val_acc: 0.8207\n",
      "Epoch 21/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5506 - acc: 0.8212 - val_loss: 0.5493 - val_acc: 0.8197\n",
      "Epoch 22/100\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5492 - acc: 0.8221 - val_loss: 0.5482 - val_acc: 0.8224\n",
      "Epoch 23/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5474 - acc: 0.8224 - val_loss: 0.5451 - val_acc: 0.8217\n",
      "Epoch 24/100\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5465 - acc: 0.8225 - val_loss: 0.5457 - val_acc: 0.8229\n",
      "Epoch 25/100\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5452 - acc: 0.8238 - val_loss: 0.5414 - val_acc: 0.8268\n",
      "Epoch 26/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5436 - acc: 0.8240 - val_loss: 0.5419 - val_acc: 0.8239\n",
      "Epoch 27/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5423 - acc: 0.8242 - val_loss: 0.5375 - val_acc: 0.8253\n",
      "Epoch 28/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5408 - acc: 0.8258 - val_loss: 0.5486 - val_acc: 0.8227\n",
      "Epoch 29/100\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5396 - acc: 0.8255\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.5396 - acc: 0.8255 - val_loss: 0.5379 - val_acc: 0.8242\n",
      "Epoch 30/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5344 - acc: 0.8276 - val_loss: 0.5346 - val_acc: 0.8263\n",
      "Epoch 31/100\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5338 - acc: 0.8271 - val_loss: 0.5347 - val_acc: 0.8256\n",
      "Epoch 32/100\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5336 - acc: 0.8273 - val_loss: 0.5337 - val_acc: 0.8273\n",
      "Epoch 33/100\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5332 - acc: 0.8278 - val_loss: 0.5347 - val_acc: 0.8263\n",
      "Epoch 34/100\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.5329 - acc: 0.8275\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5329 - acc: 0.8275 - val_loss: 0.5342 - val_acc: 0.8262\n",
      "Epoch 35/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5320 - acc: 0.8283 - val_loss: 0.5326 - val_acc: 0.8275\n",
      "Epoch 36/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5319 - acc: 0.8281 - val_loss: 0.5324 - val_acc: 0.8284\n",
      "Epoch 37/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5318 - acc: 0.8286 - val_loss: 0.5322 - val_acc: 0.8278\n",
      "Epoch 38/100\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5317 - acc: 0.8281 - val_loss: 0.5323 - val_acc: 0.8272\n",
      "Epoch 39/100\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5317 - acc: 0.8286 - val_loss: 0.5320 - val_acc: 0.8278\n",
      "Epoch 40/100\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5316 - acc: 0.8285 - val_loss: 0.5323 - val_acc: 0.8278\n",
      "Epoch 41/100\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5315 - acc: 0.8280 - val_loss: 0.5319 - val_acc: 0.8278\n",
      "Epoch 42/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5315 - acc: 0.8285 - val_loss: 0.5321 - val_acc: 0.8273\n",
      "Epoch 43/100\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.5317 - acc: 0.8286\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5315 - acc: 0.8287 - val_loss: 0.5320 - val_acc: 0.8274\n",
      "Epoch 44/100\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5312 - acc: 0.8287 - val_loss: 0.5319 - val_acc: 0.8277\n",
      "Epoch 45/100\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5312 - acc: 0.8284 - val_loss: 0.5319 - val_acc: 0.8278\n",
      "Epoch 46/100\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5311 - acc: 0.8286\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5311 - acc: 0.8286 - val_loss: 0.5319 - val_acc: 0.8276\n",
      "Epoch 47/100\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5311 - acc: 0.8285 - val_loss: 0.5319 - val_acc: 0.8277\n",
      "Epoch 48/100\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5311 - acc: 0.8284 - val_loss: 0.5319 - val_acc: 0.8277\n",
      "Epoch 49/100\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.5311 - acc: 0.8285\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5311 - acc: 0.8285 - val_loss: 0.5319 - val_acc: 0.8278\n",
      "Epoch 50/100\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5311 - acc: 0.8285 - val_loss: 0.5319 - val_acc: 0.8278\n",
      "Epoch 51/100\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5311 - acc: 0.8284 - val_loss: 0.5319 - val_acc: 0.8278\n",
      "Epoch 52/100\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.5311 - acc: 0.8284\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5311 - acc: 0.8285 - val_loss: 0.5319 - val_acc: 0.8278\n",
      "Epoch 53/100\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5311 - acc: 0.8285 - val_loss: 0.5319 - val_acc: 0.8278\n",
      "Epoch 00053: early stopping\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = model.fit(train_features_flat,train_label,epochs=NB_EPOCHS,validation_data=(val_features_flat, valid_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
