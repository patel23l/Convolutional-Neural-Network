{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e83cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16;\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcb7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc3e8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afc14414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 84), (10000, 28, 84))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX=np.dstack([trainX] * 3)\n",
    "testX=np.dstack([testX]*3)\n",
    "trainX.shape,testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352b4bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 3), (10000, 28, 28, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape images as per the tensor format required by tensorflow\n",
    "trainX = trainX.reshape(-1, 28,28,3)\n",
    "testX= testX.reshape (-1,28,28,3)\n",
    "trainX.shape,testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca1e2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 48, 48, 3), (10000, 48, 48, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize the images 48*48 as required by VGG16\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "trainX = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in trainX])\n",
    "testX = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in testX])\n",
    "#train_x = preprocess_input(x)\n",
    "trainX.shape, testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "145f53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data and change data type\n",
    "trainX = trainX / 255.\n",
    "testX = testX / 255.\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6ef4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Labels to one hot encoded format\n",
    "trainY_one_hot = to_categorical(trainY)\n",
    "testY_one_hot = to_categorical(testY)\n",
    "\n",
    "trainX,valid_X,train_label,valid_label = train_test_split(trainX,\n",
    "                                                           trainY_one_hot,\n",
    "                                                           test_size=0.2,\n",
    "                                                           random_state=13\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53541c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Finally check the data size whether it is as per tensorflow and VGG16 requirement\n",
    "trainX.shape,valid_X.shape,train_label.shape,valid_label.shape\n",
    "\n",
    "# Define the parameters for instanitaing VGG16 model. \n",
    "IMG_WIDTH = 48\n",
    "IMG_HEIGHT = 48\n",
    "IMG_DEPTH = 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Preprocessing the input \n",
    "trainX = preprocess_input(trainX)\n",
    "valid_X = preprocess_input(valid_X)\n",
    "testX  = preprocess_input (testX)\n",
    "\n",
    "#  Create base model of VGG16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False, \n",
    "                  input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH)\n",
    "                 )\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab53af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e548d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
